{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Topic number for Offensive data",
      "provenance": [],
      "authorship_tag": "ABX9TyPRUfLIMSJiKUbBc7xaTnVM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/monu322/CE888/blob/main/Assg2/OffenseDetection/Topic_number_for_Offensive_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vcc9pJXHkJvc",
        "outputId": "b479462a-52eb-4bf9-a6d0-663a7ced919b"
      },
      "source": [
        "!pip install pyLDAvis"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyLDAvis in /usr/local/lib/python3.7/dist-packages (3.3.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.0.1)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (0.0)\n",
            "Requirement already satisfied: funcy in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.15)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (0.16.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.4.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (2.11.3)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (3.6.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (56.0.0)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.20.2)\n",
            "Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.2.4)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (2.7.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->pyLDAvis) (1.1.1)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim->pyLDAvis) (5.0.0)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim->pyLDAvis) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.0->pyLDAvis) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.0->pyLDAvis) (2.8.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7rfB5iWkc3v",
        "outputId": "cdde67ae-238c-48dc-af8e-25ed6dd6b2b1"
      },
      "source": [
        "import pickle\n",
        "import gensim\n",
        "import pyLDAvis\n",
        "import pyLDAvis.gensim_models\n",
        "import spacy\n",
        "import pandas as pd\n",
        "import nltk; nltk.download('stopwords')\n",
        "import gensim.corpora as corpora\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.models import CoherenceModel\n",
        "import re\n",
        "import warnings\n",
        "from pprint import pprint\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUUoD_mOke03",
        "outputId": "682f892d-bfc0-4638-b80b-e7a74b136c15"
      },
      "source": [
        "#importing offesive dataset\n",
        "\n",
        "tweets_offensive=pd.read_fwf('https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/offensive/train_text.txt', header=None)\n",
        "print('Training tweets', tweets_offensive.shape)\n",
        "\n",
        "tweets_offensive_labels=pd.read_fwf('https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/offensive/train_labels.txt', header=None)\n",
        "print('Training labels', tweets_offensive_labels.shape)\n",
        "\n",
        "tweets_offensive_test=pd.read_fwf('https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/offensive/test_text.txt', header=None)\n",
        "print('Test tweets',tweets_offensive_test.shape)\n",
        "\n",
        "tweets_offensive_test_labels=pd.read_fwf('https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/offensive/test_labels.txt', header=None)\n",
        "print('Test labels',tweets_offensive_test_labels.shape)\n",
        "\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training tweets (11916, 51)\n",
            "Training labels (11916, 1)\n",
            "Test tweets (860, 3)\n",
            "Test labels (860, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "nnuHEnCWnHZs",
        "outputId": "a68ec5f4-7edc-4aa3-a848-d63d2c83d0df"
      },
      "source": [
        "tweets_offensive = tweets_offensive[[0]]\n",
        "tweets_offensive.head()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@user Bono... who cares. Soon people will unde...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@user Eight years the republicans denied obama...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@user Get him some line help. He is gonna be j...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@user @user She is great. Hi Fiona!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@user She has become a parody unto herself? Sh...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   0\n",
              "0  @user Bono... who cares. Soon people will unde...\n",
              "1  @user Eight years the republicans denied obama...\n",
              "2  @user Get him some line help. He is gonna be j...\n",
              "3                @user @user She is great. Hi Fiona!\n",
              "4  @user She has become a parody unto herself? Sh..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7i-19CBPoJ47",
        "outputId": "18dbe656-a6d6-4315-e829-f432db037878"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "stop_words = stopwords.words('english')\n",
        "\n",
        "def strip_newline(series):\n",
        "    return [review.replace('\\n','') for review in series]\n",
        "\n",
        "tweets_offensive[0] = strip_newline(tweets_offensive[0])\n",
        "tweets_offensive[0][20:42].values"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['@user You are so fragile. It must be hard to live that way.',\n",
              "       '@user All you do is lie. All congress does us lie.  MAGA.',\n",
              "       '@user Freudian slip.',\n",
              "       '@user @user @user @user @user @user @user @user @user @user @user @user @user @user @user @user @user @user @user @user @user @user @user @user @user @user @user @user @user @user @user @user @user @user @user @user @user @user @user @user @user @user @user @user @user @user',\n",
              "       \"@user @user Why are you wasting time replying on twitter (trolling) on behalf of people making under that amount?  Seems like someone is just a propaganda pusher...or likes gloating to other #MAGA's that they got screwed by Trump.\",\n",
              "       '@user We had Leveon Bell. Thats the dumbest argument. But we can compare college for when he played. His best season was 1700 yds 26 TDs. How about Collins? And this is Conners first year starting and he is starting much better than Collins',\n",
              "       '@user @user SHE IS A FUCKING MESS!! I HATE HER SO MUCH',\n",
              "       '@user He is so underrated and I love how pure he is as a person',\n",
              "       '@user Haha we set then ðŸ˜‚', '@user he is a psychic ainâ€™t he',\n",
              "       '@user I was think she jisoo but Iâ€™m Focused I found she is taeyoun',\n",
              "       '@user I am stunned that you are giving this guy airtime. Stunned.',\n",
              "       '@user She Wants Gun Control? Figures',\n",
              "       \"@user @user @user Didn't see him matching with antifa tbh\",\n",
              "       '@user @user @user And conservatives are no longer conservatives why do you think Maxime Bernier has started a new party that will follow original Conservative values.',\n",
              "       '@user Holy shit I love her???',\n",
              "       '@user @user @user Can you let him know?',\n",
              "       '@user @user @user @user @user @user Sir it comes to something when you present a lie as a fact.... Have you no shame? This is the fact 65% of labour voters voted to Remain. Ref YouGov polls. Your position is based on a false premise......have a nice day',\n",
              "       '@user @user A stark reminder that @user and you are trying to con us with chequers and a bit of our waters back - not good enough - @user @user  @user @user @user @user @user @user appeasing is not a good look @user',\n",
              "       \"@user @user WHERE'S holier than thou @user  Sippin wine in the shade somewhere...  #MAGA\",\n",
              "       '@user I canâ€™t cuz that nigga retarded smh',\n",
              "       '9 factory workers gunned down in Iowa City with 20-gauge Winchester pump-action shotgun. The NRA blames gun control laws.'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsCd0UWTp-pj",
        "outputId": "3380de0d-6b41-4ae4-cdb9-ebcac2cf7e15"
      },
      "source": [
        "def sent_to_words(sentences):\n",
        "    for sentence in sentences:\n",
        "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))\n",
        "\n",
        "tweet_words = list(sent_to_words(tweets_offensive[0]))\n",
        "\n",
        "tweet_words[21][:10]"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['user', 'all', 'you', 'do', 'is', 'lie', 'all', 'congress', 'does', 'us']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5eICuUyqGTo",
        "outputId": "9ca5fdaa-64fd-4afa-f68b-3c7464606ca6"
      },
      "source": [
        "def remove_stopwords(texts):\n",
        "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
        "\n",
        "tweet_words = remove_stopwords(tweet_words)\n",
        "\n",
        "def bigrams(words, bi_min=15, tri_min=10):\n",
        "    bigram = gensim.models.Phrases(words, min_count = bi_min)\n",
        "    trigram = gensim.models.Phrases(bigram[words], min_count = tri_min)\n",
        "    bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
        "    trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
        "    return bigram_mod, trigram_mod\n",
        "\n",
        "bigram_tr, trigram_tr = bigrams(tweet_words)\n",
        "\n",
        "print(trigram_tr[bigram_tr[tweet_words[0]]][:200])"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['user', 'bono', 'cares', 'soon', 'people', 'understand', 'gain', 'nothing', 'following', 'phony', 'celebrity', 'become', 'leader', 'people', 'instead', 'help', 'support', 'fellow', 'countrymen']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ko3qWBQBqLkz"
      },
      "source": [
        "nlp = spacy.load('en', disable=['parser', 'ner'])\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "def lemmatization(texts, allowed_postags=['NOUN','ADJ','VERB','ADV']):\n",
        "    texts_out = []\n",
        "    for sent in texts:\n",
        "        doc = nlp(\" \".join(sent)) \n",
        "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
        "    return texts_out\n",
        "\n",
        "trigrams_tr = [trigram_tr[bigram_tr[review]] for review in tweet_words]\n",
        "\n",
        "lemma_lg = lemmatization(trigrams_tr)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZI756LKeqOsN",
        "outputId": "8b58292e-e314-475d-efb3-a079a79f20a4"
      },
      "source": [
        "lemma_lg[0][:20]\n",
        "\n",
        "id2word_lg = gensim.corpora.Dictionary(lemma_lg)\n",
        "id2word_lg.filter_extremes(no_below=10, no_above=0.35)\n",
        "id2word_lg.compactify()\n",
        "id2word_lg.save('train_dict_lg')\n",
        "corpus_lg = [id2word_lg.doc2bow(text) for text in lemma_lg]\n",
        "\n",
        "corpus_lg[22][:20]"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QRR6pK5ptES2",
        "outputId": "82b7de45-a488-4054-d6dd-4a371ec03d34"
      },
      "source": [
        "from gensim.models import HdpModel\n",
        "hdp = HdpModel(corpus_lg, id2word_lg, chunksize=10000)\n",
        "\n",
        "len(hdp.print_topics())"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xnatra09tIq3",
        "outputId": "eb4c68fd-3f98-4a23-8faf-84d058c8d8f6"
      },
      "source": [
        "hdp.print_topics(num_topics=20)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0,\n",
              "  '0.006*opposite + 0.005*rapist + 0.005*somehow + 0.004*almost + 0.004*regard + 0.004*finally + 0.004*holder + 0.004*rather + 0.004*traitor + 0.004*mad'),\n",
              " (1,\n",
              "  '0.006*course + 0.005*reason + 0.005*excuse + 0.005*ill + 0.005*picture + 0.004*boy + 0.004*liberal + 0.004*stand + 0.004*insane + 0.004*forever'),\n",
              " (2,\n",
              "  '0.006*completely + 0.005*growth + 0.005*hunt + 0.005*bigot + 0.005*regard + 0.004*later + 0.004*remind + 0.004*attempt + 0.004*last + 0.004*brown'),\n",
              " (3,\n",
              "  '0.007*woman + 0.006*pm + 0.005*dead + 0.005*promise + 0.004*stock + 0.004*economy + 0.004*yesterday + 0.004*screw + 0.004*decide + 0.004*invite'),\n",
              " (4,\n",
              "  '0.006*socialist + 0.005*year_old + 0.005*wake + 0.004*clean + 0.004*nee + 0.004*instead + 0.004*mother + 0.004*protection + 0.004*fair + 0.004*profit'),\n",
              " (5,\n",
              "  '0.006*usual + 0.005*weapon + 0.004*one + 0.004*could + 0.004*choice + 0.004*recognize + 0.004*exist + 0.004*connect + 0.004*gun_control_laws + 0.004*however'),\n",
              " (6,\n",
              "  '0.005*measure + 0.005*fake + 0.004*together + 0.004*serious + 0.004*least + 0.004*admit + 0.004*show + 0.004*company + 0.004*job + 0.004*lawyer'),\n",
              " (7,\n",
              "  '0.005*thought + 0.005*unethical + 0.004*connect + 0.004*successful + 0.004*blue + 0.004*left + 0.004*cause + 0.004*soul + 0.004*problem + 0.004*crime'),\n",
              " (8,\n",
              "  '0.006*opposite + 0.005*evil + 0.005*model + 0.004*multiple + 0.004*court + 0.004*ca + 0.004*wave + 0.004*completely + 0.004*raise + 0.004*political'),\n",
              " (9,\n",
              "  '0.007*disgrace + 0.005*effort + 0.005*apply + 0.004*train + 0.004*piss + 0.004*cut + 0.004*bigot + 0.004*dare + 0.004*reveal + 0.004*mention'),\n",
              " (10,\n",
              "  '0.005*thread + 0.005*none + 0.004*make + 0.004*trump + 0.004*potu + 0.004*grade + 0.004*funny + 0.004*lady + 0.003*straight + 0.003*ask'),\n",
              " (11,\n",
              "  '0.006*love + 0.004*thug + 0.004*test + 0.004*ownership + 0.004*dark + 0.004*raise + 0.004*position + 0.004*non + 0.004*true + 0.004*breath'),\n",
              " (12,\n",
              "  '0.007*spending + 0.006*half + 0.006*often + 0.005*abortion + 0.004*water + 0.004*nation + 0.004*somewhere + 0.004*fake + 0.004*could + 0.004*title'),\n",
              " (13,\n",
              "  '0.005*resist + 0.005*listen + 0.005*sexually + 0.004*sorry + 0.004*follow + 0.004*argue + 0.004*dog + 0.004*disagree + 0.004*subject + 0.004*approve'),\n",
              " (14,\n",
              "  '0.006*immigrant + 0.006*effort + 0.005*global + 0.005*political + 0.004*assault + 0.004*bitter + 0.004*shitty + 0.004*guilty + 0.004*average + 0.004*people'),\n",
              " (15,\n",
              "  '0.005*post + 0.004*nation + 0.004*listen + 0.004*accountable + 0.004*value + 0.004*explain + 0.004*silent + 0.003*folk + 0.003*condemn + 0.003*middle'),\n",
              " (16,\n",
              "  '0.004*pull + 0.004*close + 0.004*credibility + 0.004*class + 0.004*strong + 0.004*sink + 0.004*interest + 0.003*win + 0.003*welcome + 0.003*wealth'),\n",
              " (17,\n",
              "  '0.009*smoke + 0.005*forget + 0.004*quite + 0.004*failure + 0.004*front + 0.004*spend + 0.004*mouth + 0.004*knee + 0.004*nice + 0.004*piece'),\n",
              " (18,\n",
              "  '0.006*prevent + 0.005*speak + 0.005*connection + 0.005*strike + 0.004*ppl + 0.004*piss + 0.004*act + 0.004*document + 0.004*embarrassment + 0.004*illegal'),\n",
              " (19,\n",
              "  '0.005*ago + 0.005*use + 0.005*tear + 0.005*best + 0.005*warn + 0.004*cross + 0.004*liar + 0.004*hand + 0.004*suppose + 0.004*hero')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    }
  ]
}